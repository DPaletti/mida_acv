{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AecmabYVurev"
   },
   "source": [
    "# Sustainable Mobility: classification of electric scooter rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy7bS0L91jmM"
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCbw2yn3urez",
    "outputId": "fca3f7f3-c65e-4a94-f3a1-5d8a771967cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mida_acv'...\n",
      "remote: Enumerating objects: 249, done.\u001B[K\n",
      "remote: Counting objects: 100% (54/54), done.\u001B[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001B[K\n",
      "remote: Total 249 (delta 6), reused 46 (delta 2), pack-reused 195\u001B[K\n",
      "Receiving objects: 100% (249/249), 250.21 MiB | 26.30 MiB/s, done.\n",
      "Resolving deltas: 100% (23/23), done.\n",
      "Checking out files: 100% (162/162), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DPaletti/mida_acv\n",
    "!mv mida_acv/data .\n",
    "!yes|rm -r mida_acv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieNbtN1s2AQp"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XAlrODCD2DWm",
    "outputId": "359b3b52-b1d2-4ca3-b825-ad8c0d029037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tsfresh\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/22/7f/53e845c3e19078d15e228db642ad06d5a91207a66115cb4f30a2eca28f17/tsfresh-0.18.0-py2.py3-none-any.whl (94kB)\n",
      "\u001B[K     |████████████████████████████████| 102kB 4.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: dask[dataframe]>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (2.12.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.10.2)\n",
      "Collecting distributed>=2.11.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/0c/b0/3454dc44239c526f9c9e4cf04f62823776b71f927db74302986d56e7a9a1/distributed-2021.4.0-py3-none-any.whl (684kB)\n",
      "\u001B[K     |████████████████████████████████| 686kB 11.0MB/s \n",
      "\u001B[?25hCollecting stumpy>=1.7.2\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/4c/da/8d372a1af518930ecb3ad9acc627115450149b613ba1b9b51b4d3721218e/stumpy-1.8.0-py3-none-any.whl (94kB)\n",
      "\u001B[K     |████████████████████████████████| 102kB 9.3MB/s \n",
      "\u001B[?25hRequirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.22.2.post1)\n",
      "Collecting matrixprofile>=1.1.10<2.0.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/b1/c3/43d282f0e5299f977b62e53e4dde22ddb14c90877af5b62af225fa783d8e/matrixprofile-1.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.1MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1MB 49.6MB/s \n",
      "\u001B[?25hRequirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (2.23.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh) (4.41.1)\n",
      "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
      "\u001B[K     |████████████████████████████████| 112kB 56.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.9.0->tsfresh) (0.11.1)\n",
      "Collecting partd>=0.3.10; extra == \"dataframe\"\n",
      "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (2.0.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (1.7.0)\n",
      "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (5.1.1)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (3.13)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (2.3.0)\n",
      "Collecting cloudpickle>=1.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (54.2.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (1.0.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh) (5.4.8)\n",
      "Requirement already satisfied: numba>=0.48 in /usr/local/lib/python3.7/dist-packages (from stumpy>=1.7.2->tsfresh) (0.51.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.0.1)\n",
      "Collecting protobuf==3.11.2\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/4a/14/f5c294f1e36a031f165128c25feba93b3116f15a74398d0b2747ed75744f/protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3MB 41.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from matrixprofile>=1.1.10<2.0.0->tsfresh) (3.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->tsfresh) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->tsfresh) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->tsfresh) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.1)\n",
      "Collecting locket\n",
      "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.11.0->tsfresh) (1.0.1)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48->stumpy>=1.7.2->tsfresh) (0.34.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->matrixprofile>=1.1.10<2.0.0->tsfresh) (0.10.0)\n",
      "\u001B[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001B[0m\n",
      "\u001B[31mERROR: google-api-core 1.26.3 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.2 which is incompatible.\u001B[0m\n",
      "\u001B[31mERROR: distributed 2021.4.0 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001B[0m\n",
      "\u001B[31mERROR: stumpy 1.8.0 has requirement scipy>=1.5, but you'll have scipy 1.4.1 which is incompatible.\u001B[0m\n",
      "Installing collected packages: cloudpickle, distributed, stumpy, protobuf, matrixprofile, tsfresh, fsspec, locket, partd\n",
      "  Found existing installation: cloudpickle 1.3.0\n",
      "    Uninstalling cloudpickle-1.3.0:\n",
      "      Successfully uninstalled cloudpickle-1.3.0\n",
      "  Found existing installation: distributed 1.25.3\n",
      "    Uninstalling distributed-1.25.3:\n",
      "      Successfully uninstalled distributed-1.25.3\n",
      "  Found existing installation: protobuf 3.12.4\n",
      "    Uninstalling protobuf-3.12.4:\n",
      "      Successfully uninstalled protobuf-3.12.4\n",
      "Successfully installed cloudpickle-1.6.0 distributed-2021.4.0 fsspec-2021.4.0 locket-0.2.1 matrixprofile-1.1.10 partd-1.2.0 protobuf-3.11.2 stumpy-1.8.0 tsfresh-0.18.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdp\n",
      "  Downloading https://files.pythonhosted.org/packages/67/42/80a54cc4387256335c32b48bd42db80967ab5f40d6ffcd8167b3dd988c11/rdp-0.8.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rdp) (1.19.5)\n",
      "Building wheels for collected packages: rdp\n",
      "  Building wheel for rdp (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for rdp: filename=rdp-0.8-cp37-none-any.whl size=4569 sha256=d7a5b95ca54277be3d2d3f893c75942f024e2b3a3d55949cfb572c81dcfcbd8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/e4/02/c738593caece49c63180d093651bec3cd3b02ea3248f076f07\n",
      "Successfully built rdp\n",
      "Installing collected packages: rdp\n",
      "Successfully installed rdp-0.8\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (4.4.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
      "Collecting sktime\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/ed/0b/ee4c2a9f2ef22eea4e202c4740142f3dfb8a3e5f9f1b36731b39b58ca432/sktime-0.6.0-cp37-cp37m-manylinux2014_x86_64.whl (5.7MB)\n",
      "\u001B[K     |████████████████████████████████| 5.7MB 4.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.51.2)\n",
      "Collecting statsmodels>=0.12.1\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/da/69/8eef30a6237c54f3c0b524140e2975f4b1eea3489b45eb3339574fc8acee/statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
      "\u001B[K     |████████████████████████████████| 9.5MB 39.8MB/s \n",
      "\u001B[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
      "Collecting scikit-learn>=0.24.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
      "\u001B[K     |████████████████████████████████| 22.3MB 1.2MB/s \n",
      "\u001B[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (54.2.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (0.34.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->sktime) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels>=0.12.1->sktime) (1.15.0)\n",
      "Installing collected packages: statsmodels, threadpoolctl, scikit-learn, sktime\n",
      "  Found existing installation: statsmodels 0.10.2\n",
      "    Uninstalling statsmodels-0.10.2:\n",
      "      Successfully uninstalled statsmodels-0.10.2\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed scikit-learn-0.24.1 sktime-0.6.0 statsmodels-0.12.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tsfresh\n",
    "!pip install rdp\n",
    "!pip install plotly\n",
    "!pip install joblib\n",
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xV2MjmrG2HSv"
   },
   "outputs": [],
   "source": [
    "# After installing tsfresh runtime needs to be restarted\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckdclAM02OH4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RlA48MU22U1u"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict, Optional\n",
    "from tempfile import mkdtemp\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import tsfresh as ts\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import plotly as plt\n",
    "import rdp\n",
    "import plotly.graph_objects as go\n",
    "import joblib\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import sklearn.linear_model\n",
    "#import sktime as skt\n",
    "#import sktime.forecasting.model_selection\n",
    "import scipy.signal\n",
    "import tsfresh.feature_extraction\n",
    "from itertools import repeat\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "plt.io.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-JnwG8QbhYZ"
   },
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN6Zz--h2qUy"
   },
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cle0PIgg2tOt"
   },
   "outputs": [],
   "source": [
    "def read_data(data_path: str):\n",
    "  X = pd.DataFrame()\n",
    "  y_weight=pd.Series(dtype=np.float64)\n",
    "  y_passengers=pd.Series(dtype=np.int64)\n",
    "  y_weight_deck=pd.Series(dtype=np.float64)\n",
    "  y_passengers_deck=pd.Series(dtype=np.int64)\n",
    "  y_weight_stem=pd.Series(dtype=np.float64)\n",
    "  y_passengers_stem=pd.Series(dtype=np.int64)\n",
    "  curr_X = pd.DataFrame()\n",
    "  i: int = 0\n",
    "  for placement in {\"deck\", \"stem\"}:\n",
    "      for driver_number in {\"single\", \"double\"}:\n",
    "          for ds in Path(data_path).joinpath(placement, driver_number).iterdir():\n",
    "              curr_X = pd.read_csv(str(ds))\n",
    "              curr_X = curr_X.assign(id=i)\n",
    "              curr_X = curr_X.assign(full_id=placement + \"-\" + driver_number + \"-\" + curr_X[\"Driver\"][0])\n",
    "              curr_X = curr_X.assign(IsDeck=0 if placement == \"deck\" else 1)\n",
    "              y_weight.at[i] = curr_X[\"Weight\"][0]\n",
    "              y_passengers.at[i] = 0 if driver_number==\"single\" else 1\n",
    "              if placement == \"deck\":\n",
    "                y_weight_deck.at[i] = curr_X[\"Weight\"][0]\n",
    "                y_passengers_deck.at[i] = 0 if driver_number==\"single\" else 1\n",
    "              else:\n",
    "                y_weight_stem.at[i] = curr_X[\"Weight\"][0]\n",
    "                y_passengers_stem.at[i] = 0 if driver_number==\"single\" else 1\n",
    "                \n",
    "\n",
    "              curr_X = curr_X.drop(\n",
    "                  [\"Unnamed: 0\", \"Driver\", \"Placement\", \"Weight\"], \n",
    "                  axis=1\n",
    "              )\n",
    "              X = X.append(curr_X)\n",
    "              i += 1\n",
    "  to_weight_class =(lambda x: 0 if x<70 else (1 if (x>=70 and x<90) else (2 if (x>=90 and x<110) else 3)))\n",
    "  return (X.fillna(0),\n",
    "          X.fillna(0).groupby(\"id\").filter(lambda group: group[\"full_id\"][0].split(\"-\")[0] == \"deck\").drop(\"IsDeck\", axis=1), \n",
    "          X.fillna(0).groupby(\"id\").filter(lambda group: group[\"full_id\"][0].split(\"-\")[0] == \"stem\").drop(\"IsDeck\", axis=1), \n",
    "          y_weight.fillna(0).map(to_weight_class), \n",
    "          y_passengers.fillna(0),\n",
    "          y_weight_deck.fillna(0).map(to_weight_class),\n",
    "          y_passengers_deck.fillna(0),\n",
    "          y_weight_stem.fillna(0).map(to_weight_class),\n",
    "          y_passengers_stem.fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFBJSPnJFFIY"
   },
   "source": [
    "### Align signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iNWrQw4wFG6S"
   },
   "outputs": [],
   "source": [
    "def align_signal(signal_1: np.array, signal_2: np.array, col_name:str):\n",
    "  signal_1 = (signal_1 - np.mean(signal_1))/np.std(signal_1)\n",
    "  signal_2 = (signal_2 - np.mean(signal_2))/np.std(signal_2)\n",
    "  shift = np.argmax(np.convolve(signal_1[::-1],signal_2,mode='valid'))\n",
    "  return np.append([0]*shift, signal_2[shift: ]), col_name\n",
    "\n",
    "def align(X: pd.DataFrame):\n",
    "  out_X = pd.DataFrame(columns=X.columns)\n",
    "  columns_to_ignore = [\"full_id\", \"IsDeck\", \"Timestamp\", \"id\", \"Latitude\", \"Longitude\", \"Speed\", \"Confidence\"]\n",
    "  for ts in [x for _, x in X.groupby(\"id\").filter(lambda group: group[\"full_id\"][0].split(\"-\")[0]==\"deck\").groupby(\"id\")]:\n",
    "    full_id = ts[\"full_id\"][0].split(\"-\")\n",
    "    for ts_to_align in [x for _, x in X.groupby(\"id\").filter(lambda group: group[\"full_id\"][0].split(\"-\")[0]==\"stem\").groupby(\"id\")]:\n",
    "      full_id_to_align = ts_to_align[\"full_id\"][0].split(\"-\")\n",
    "      if full_id[1:] == full_id_to_align[1:]:\n",
    "        ts_signals = ts.drop(columns_to_ignore, axis=1)\n",
    "        ts_to_align_signals = ts_to_align.drop(columns_to_ignore, axis=1)\n",
    "        with multiprocessing.Pool(multiprocessing.cpu_count()) as p:\n",
    "          aligned_signals = (p.starmap(align_signal, \n",
    "                            [(ts_item[1], ts_to_align_item[1], ts_to_align_item[0])\n",
    "                            for ts_item, ts_to_align_item \n",
    "                            in zip(ts_signals.iteritems(), ts_to_align_signals.iteritems())]))\n",
    "        temp_ts = pd.DataFrame(columns=ts_to_align.columns)\n",
    "        temp_ts[columns_to_ignore] = ts_to_align[columns_to_ignore]\n",
    "        \n",
    "        for aligned_signal, col in aligned_signals:\n",
    "          temp_ts[col] = aligned_signal\n",
    "        out_X = out_X.append(ts)\n",
    "        out_X = out_X.append(temp_ts)\n",
    "  return out_X,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuESplwo2-eT"
   },
   "source": [
    "### Path simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s4gnCwrs3rXD"
   },
   "outputs": [],
   "source": [
    "def get_path(X: pd.DataFrame) -> np.array:\n",
    "    out = []\n",
    "    for index, row in X.iterrows():\n",
    "        out.append((row[\"Latitude\"], row[\"Longitude\"]))\n",
    "    return np.array(out)\n",
    "\n",
    "def simplify_path(X: pd.DataFrame,epsilon: float = 1e-6):\n",
    "    if epsilon <= 0:\n",
    "      return X\n",
    "    out_df: pd.DataFrame = pd.DataFrame()\n",
    "    for df in [x for _, x in X.groupby([\"id\"])]:\n",
    "      print(\"Simplifying: \" + df[\"full_id\"][0])\n",
    "      df = df[rdp.rdp(get_path(df), epsilon=epsilon, return_mask=True)]\n",
    "      out_df = out_df.append(df)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-bYB5m38gTK"
   },
   "source": [
    "### Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mQmcXCu28mEM"
   },
   "outputs": [],
   "source": [
    "def window(X: pd.DataFrame,\n",
    "           y_weight: pd.Series,\n",
    "           y_passengers: pd.Series,\n",
    "           rolling_direction: int=1,\n",
    "           min_timeshift: int=0,\n",
    "           max_timeshift: Optional[int] = None):\n",
    "\n",
    "    X_rolled = ts.utilities.dataframe_functions.roll_time_series(\n",
    "            X,\n",
    "            column_id=\"id\",\n",
    "            column_sort=\"Timestamp\",\n",
    "            column_kind=None,\n",
    "            min_timeshift=min_timeshift,\n",
    "            max_timeshift=max_timeshift,\n",
    "            rolling_direction=rolling_direction,\n",
    "            n_jobs=multiprocessing.cpu_count(),\n",
    "        )\n",
    "\n",
    "    y_weight_out = np.empty([0])\n",
    "    y_passengers_out = np.empty([0])\n",
    "\n",
    "    for df in [x for _, x in X_rolled.groupby([\"id\"])]:\n",
    "        ident = df[\"id\"].values[0][0]\n",
    "        y_weight_out = np.append(y_weight_out, y_weight[ident])\n",
    "        y_passengers_out = np.append(y_passengers_out, y_passenger[ident])\n",
    "    return X_rolled, y_weight_out, y_passengers_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsv6GEwg930O"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fadneckj95-Z"
   },
   "outputs": [],
   "source": [
    "def extract_features(X: pd.DataFrame):\n",
    "  return ts.extract_features(\n",
    "          X,\n",
    "          column_id=\"id\",\n",
    "          column_sort=\"Timestamp\",\n",
    "          n_jobs=multiprocessing.cpu_count(),\n",
    "          default_fc_parameters=ts.feature_extraction.MinimalFCParameters()\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLRlMgWB_-R_"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oJ07ehYrAHhL"
   },
   "outputs": [],
   "source": [
    "def select_features(X: pd.DataFrame, y: np.array):\n",
    "  return ts.select_features(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkqpaGo1z4SY"
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nlUt2ZRK0xLd"
   },
   "outputs": [],
   "source": [
    "def visualize_signal(\n",
    "    df: pd.DataFrame, signal: str, unit: str, label, *args: Tuple[pd.DataFrame, str]\n",
    "):\n",
    "    fig = go.Figure(\n",
    "        go.Scatter(\n",
    "            mode=\"markers+lines\",\n",
    "            x=df[\"Timestamp\"],\n",
    "            y=df[signal if signal not in {\"A\", \"G\", \"Jerk_\"} else signal + \"x\"],\n",
    "            marker={\"size\": 3},\n",
    "            name=label,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis={\"title\": \"Time (s)\"},\n",
    "        yaxis={\"title\": signal.replace(\"_\", \"\") + \" (\" + unit + \")\"},\n",
    "        width=1920,\n",
    "        height=1080,\n",
    "        font=dict(size=18),\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "\n",
    "    if signal not in {\"A\", \"G\", \"Jerk_\"}:\n",
    "        for _df, _label in args:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    mode=\"markers+lines\",\n",
    "                    x=_df[\"Timestamp\"],\n",
    "                    y=_df[signal],\n",
    "                    marker={\"size\": 3},\n",
    "                    name=_label,\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        dfs: List[pd.DataFrame] = []\n",
    "        labels: List[str] = []\n",
    "        for t in args:\n",
    "            dfs.append(t[0])\n",
    "            labels.append(t[1])\n",
    "        for _df, _label, axis in zip(dfs, labels, [\"y\", \"z\"]):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    mode=\"markers+lines\",\n",
    "                    x=_df[\"Timestamp\"],\n",
    "                    y=_df[\"Speed\" if signal == \"Speed\" else signal + axis],\n",
    "                    marker={\"size\": 3},\n",
    "                    name=_label,\n",
    "                )\n",
    "            )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L77MwDC-e0h"
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1BGhMlYazQg"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A0kFeSeha214"
   },
   "outputs": [],
   "source": [
    "X, X_deck, X_stem, y_weight, y_passenger, y_weight_deck, y_passengers_deck, y_weight_stem, y_passengers_stem = read_data(\"./data/simplified_datasets_1e-06\")\n",
    "#X_aligned = align(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     3\n",
      "2     2\n",
      "3     1\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    0\n",
      "12    1\n",
      "13    2\n",
      "14    3\n",
      "15    1\n",
      "16    1\n",
      "17    0\n",
      "18    2\n",
      "19    1\n",
      "20    0\n",
      "21    0\n",
      "22    3\n",
      "23    1\n",
      "24    2\n",
      "25    0\n",
      "26    1\n",
      "27    0\n",
      "28    1\n",
      "29    0\n",
      "30    2\n",
      "31    1\n",
      "32    1\n",
      "33    1\n",
      "34    0\n",
      "35    1\n",
      "36    1\n",
      "37    3\n",
      "38    1\n",
      "39    0\n",
      "40    2\n",
      "41    1\n",
      "42    1\n",
      "43    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfRMIBlrsIy-"
   },
   "source": [
    "### Path simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "6WlieS-1sLDM",
    "outputId": "f6233c80-fe7b-4155-9546-284068f68f13",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simplify_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-c1144890025a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mX_deck_simplified\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msimplify_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_deck\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'simplify_path' is not defined"
     ]
    }
   ],
   "source": [
    "X_deck_simplified = simplify_path(X_deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Jb6W26yp8-b"
   },
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JO9ppftkwXIl",
    "outputId": "a5bbc5bb-6142-4440-c969-fedb440695c5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dpaletti/mida_acv/.venv/lib/python3.9/site-packages/tsfresh/utilities/dataframe_functions.py:456: UserWarning:\n",
      "\n",
      "Your time stamps are not uniformly sampled, which makes rolling nonsensical in some domains.\n",
      "\n",
      "Rolling: 100%|██████████| 38/38 [00:01<00:00, 19.05it/s]\n",
      "Rolling: 100%|██████████| 39/39 [00:02<00:00, 17.70it/s]\n"
     ]
    }
   ],
   "source": [
    "X_deck_windowed, y_weight_deck_windowed, y_passengers_deck_windowed = window(X_deck, y_weight_deck, y_passengers_deck, rolling_direction=1, min_timeshift=20,max_timeshift=20)\n",
    "X_stem_windowed, y_weight_stem_windowed, y_passengers_stem_windowed = window(X_stem, y_weight_stem, y_passengers_stem, rolling_direction=1, min_timeshift=20,max_timeshift=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeR5UgXpWqtJ"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khzMW8miWtLw",
    "outputId": "4c7939e1-f6c8-454d-e9d2-f06fad38187e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:13<00:00,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "deck_features = extract_features(X_deck_windowed.drop(\"full_id\", axis=1))\n",
    "stem_features = extract_features(X_stem_windowed.drop(\"full_id\", axis=1))\n",
    "deck_features.to_csv(\"features_deck_minimal.csv\")\n",
    "stem_features.to_csv(\"features_stem_minimal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7185"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "h4z4thdbcA6T",
    "outputId": "5b708485-041d-4449-9646-b20b1b931f49"
   },
   "outputs": [],
   "source": [
    "weight_stem_features = select_features(stem_features, y_weight_stem_windowed)\n",
    "weight_stem_features.to_csv(\"selected_features_stem_windowed_20_weight.csv\")\n",
    "passengers_stem_features = select_features(stem_features, y_passengers_stem_windowed)\n",
    "passengers_stem_features.to_csv(\"selected_features_stem_windowed_20_passengers.csv\")\n",
    "weight_deck_features = select_features(deck_features, y_weight_deck_windowed)\n",
    "weight_deck_features.to_csv(\"selected_features_deck_windowed_20_weight.csv\")\n",
    "passengers_deck_features = select_features(deck_features, y_passengers_deck_windowed)\n",
    "passengers_deck_features.to_csv(\"selected_features_deck_windowed_20_passengers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ9jcaifa4pP"
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDgJYXjEa7Bb"
   },
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = joblib.Memory(location=cachedir, verbose=10)\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline([#(\"align\", sk.preprocessing.FunctionTransformer(align))\n",
    "                                 (\"windowing\", skt.forecasting.model_selection.SlidingWindowSplitter),\n",
    "                                 (\"simplify_paths\", sk.preprocessing.FunctionTransformer(simplify_path)),\n",
    "                                 (\"extract_features\", sk.preprocessing.FunctionTransformer(extract_features)),\n",
    "                                 (\"pca\", sk.decomposition.PCA()),\n",
    "                                 #(\"select_features\", sk.preprocessing.FunctionTransformer(select_features)),\n",
    "                                 (\"logistic_regression\", sk.linear_model.LogisticRegression(max_iter=10000, tol=0.1))],\n",
    "                                memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ynbr50SYbEoX"
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "6wVglUMM-hkx",
    "outputId": "1d2a0aad-23bb-4b1a-decd-44119676814f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-131-20648c875210>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m }\n\u001B[1;32m      8\u001B[0m \u001B[0msearch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_selection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0msearch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_passenger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_passenger\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"window__min_timeshift\": [0, 10, 100, 1000, 10000],\n",
    "    \"window__max_timeshift\": [None, 10, 100, 1000, 10000],\n",
    "    \"simplify_paths\": [0, 1e-6, 1e-9, 1e-12, 1e-15],\n",
    "    \"pca__n_components\": [5, 15, 30, 45, 64],\n",
    "    \"logistic__C\": np.logspace(-4, 4, 4),\n",
    "}\n",
    "search = sk.model_selection.GridSearchCV(pipeline, param_grid, n_jobs=-1)\n",
    "search.fit(pd.DataFrame, y_passenger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FnNSDTJbIGF"
   },
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjtPLIymbJ3p"
   },
   "source": [
    "#### Weight Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m68hhRX2bMU4"
   },
   "outputs": [],
   "source": [
    "search.fit(X, y_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMtizbqHbOlG"
   },
   "source": [
    "####Passenger Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1Cb-cVzbRwv"
   },
   "outputs": [],
   "source": [
    "search.fit(X, y_passenger)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Gy7bS0L91jmM",
    "MuESplwo2-eT",
    "7-bYB5m38gTK",
    "xsv6GEwg930O",
    "kLRlMgWB_-R_",
    "dkqpaGo1z4SY",
    "2FnNSDTJbIGF"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "mida_acv.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PyCharm (mida_acv)",
   "language": "python",
   "name": "pycharm-ee09a8a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}